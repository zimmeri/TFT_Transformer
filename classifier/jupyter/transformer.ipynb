{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2HVcVLblyW-",
        "outputId": "8618002a-4b4f-4841-d7b1-7731363029a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Aex8OLaEfn7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import optuna\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIBYwnivEi9S",
        "outputId": "44f79727-02f7-4eef-af3a-50ce17b98137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Gwg-q32FeNO"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module): #build a transformer block with dropout and normilization\n",
        "    def __init__(self, input_dim, num_heads, ffn_dim, dropout):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=input_dim, num_heads=num_heads, dropout=dropout) #multi-head self-attention layer\n",
        "        self.norm1 = nn.LayerNorm(input_dim) #first normalization after attention\n",
        "        self.norm2 = nn.LayerNorm(input_dim) #second normalization after FFN\n",
        "        self.ffn = nn.Sequential( #feed-forward network with ReLU activation\n",
        "            nn.Linear(input_dim, ffn_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ffn_dim, input_dim)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout) #dropout for regularization\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output, _ = self.attention(x, x, x) #self-attention: query, key, value are the same\n",
        "        x = self.norm1(x + self.dropout(attn_output)) #dropout + norm after attention\n",
        "\n",
        "        ffn_output = self.ffn(x) #pass through feed-forward network\n",
        "        x = self.norm2(x + self.dropout(ffn_output)) #dropout + norm after FFN\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerMLP(nn.Module): #transformer MLP for numerical data\n",
        "    def __init__(self, input_dim=62, hidden_dim=128, num_heads=4, num_layers=2, ffn_dim=128, dropout=0.1, output_dim=8):\n",
        "        super(TransformerMLP, self).__init__()\n",
        "\n",
        "        assert hidden_dim % num_heads == 0, \"hidden_dim must be divisible by num_heads\" #assertion for optuna optimization, otherwise model will error\n",
        "\n",
        "        #standard transformer with embedding layer, attention heads, and output layer\n",
        "        self.embedding = nn.Linear(input_dim, hidden_dim) #linear layer to project input into hidden_dim\n",
        "        self.transformer_layers = nn.ModuleList([ #stack of transformer blocks\n",
        "            TransformerBlock(hidden_dim, num_heads, ffn_dim, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim) #final linear layer for output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) #project input to hidden space\n",
        "        x = x.unsqueeze(1) #add sequence dimension (seq_len=1 for tabular input)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x) #pass through each transformer block\n",
        "\n",
        "        x = x.squeeze(1) #remove sequence dimension\n",
        "        x = self.fc(x) #map to output dimension\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT1GbiWYJJr8"
      },
      "outputs": [],
      "source": [
        "#standard train loop\n",
        "def train(model, data_loader, crit, opt, device): #model, trainset data loader, criterion, optimizer, device\n",
        "  model.train()\n",
        "  total_loss, correct, total = 0, 0, 0\n",
        "  total_size = len(data_loader)\n",
        "  for data, label in data_loader:\n",
        "    data= data.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    opt.zero_grad()\n",
        "\n",
        "    out = model(data)\n",
        "    loss = crit(out, label)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    _, y = torch.max(out, 1)\n",
        "    total += label.size(0)\n",
        "    correct += (y == label).sum().item()\n",
        "\n",
        "  epoch_loss = total_loss / total_size\n",
        "  epoch_score = correct/total\n",
        "\n",
        "  return epoch_loss, epoch_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1FNzhXBP_VZ"
      },
      "outputs": [],
      "source": [
        "#standard eval loop\n",
        "def eval(model, data_loader, crit, device): #model, testset data loader, criterion, device\n",
        "  model.eval()\n",
        "  total_loss, correct, total = 0, 0, 0\n",
        "  total_size = len(data_loader)\n",
        "  with torch.no_grad():\n",
        "    for data, label in data_loader:\n",
        "      data= data.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      out = model(data)\n",
        "      loss = crit(out, label)\n",
        "\n",
        "      total_loss += loss.item()\n",
        "      _, y = torch.max(out, 1)\n",
        "      total += label.size(0)\n",
        "      correct += (y == label).sum().item()\n",
        "\n",
        "  epoch_loss = total_loss / total_size\n",
        "  epoch_score = correct/total\n",
        "  return epoch_loss, epoch_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCEDMibvQOKz"
      },
      "outputs": [],
      "source": [
        "def run_model(model, train_loader, test_loader, epochs, crit, opt, device):\n",
        "  final_test_score = 0\n",
        "  for epoch in range(epochs):\n",
        "    train_loss, train_score = train(model, train_loader, crit, opt, device)\n",
        "    test_loss, test_score = eval(model, test_loader, crit, device)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{epochs}')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Score: {train_score:.4f}')\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Score: {test_score:.4f}')\n",
        "    final_test_score = test_score\n",
        "  return final_test_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3mdReUDQiTy"
      },
      "outputs": [],
      "source": [
        "#Custom pandas dataset given csvs are read in as dataframes\n",
        "class PandasDataset(Dataset):\n",
        "    def __init__(self, dataframe, target_column=None):\n",
        "        self.features = dataframe.drop(columns=[target_column]).values if target_column else dataframe.values\n",
        "        self.features = torch.tensor(self.features, dtype=torch.float)\n",
        "\n",
        "        if target_column:\n",
        "            self.labels = torch.tensor(dataframe[target_column].values, dtype=torch.int64)\n",
        "        else:\n",
        "            self.labels = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is not None:\n",
        "            return self.features[idx], self.labels[idx]\n",
        "        return self.features[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "bQPvpr-qQrk6",
        "outputId": "a9793e53-74b0-4a12-b0e8-a863d9dd90a0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "match_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-113a10cd-648e-477e-9bc9-0f79f1c2fb95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Champion 1_0</th>\n",
              "      <th>Champion 1_1</th>\n",
              "      <th>Champion 1_2</th>\n",
              "      <th>Champion 1_3</th>\n",
              "      <th>Champion 1_4</th>\n",
              "      <th>Champion 1_5</th>\n",
              "      <th>Champion 1_6</th>\n",
              "      <th>Level 1</th>\n",
              "      <th>Item 1 1_0</th>\n",
              "      <th>Item 1 1_1</th>\n",
              "      <th>...</th>\n",
              "      <th>Trait 7_3</th>\n",
              "      <th>Trait 7_4</th>\n",
              "      <th>Tier 7</th>\n",
              "      <th>Trait 8_0</th>\n",
              "      <th>Trait 8_1</th>\n",
              "      <th>Trait 8_2</th>\n",
              "      <th>Trait 8_3</th>\n",
              "      <th>Trait 8_4</th>\n",
              "      <th>Tier 8</th>\n",
              "      <th>Placement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270891</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270892</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270893</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270894</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270895</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270896 rows × 394 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-113a10cd-648e-477e-9bc9-0f79f1c2fb95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-113a10cd-648e-477e-9bc9-0f79f1c2fb95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-113a10cd-648e-477e-9bc9-0f79f1c2fb95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6fa76bde-3743-41b4-9cf3-9d56e2f7ed19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6fa76bde-3743-41b4-9cf3-9d56e2f7ed19')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6fa76bde-3743-41b4-9cf3-9d56e2f7ed19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ac6f7936-1a62-4fb9-b8b5-03dc43861d91\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('match_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ac6f7936-1a62-4fb9-b8b5-03dc43861d91 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('match_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        Champion 1_0  Champion 1_1  Champion 1_2  Champion 1_3  Champion 1_4  \\\n",
              "0                  0             0             0             0             0   \n",
              "1                  0             0             0             0             0   \n",
              "2                  0             0             0             0             0   \n",
              "3                  0             0             0             0             1   \n",
              "4                  0             0             0             0             0   \n",
              "...              ...           ...           ...           ...           ...   \n",
              "270891             0             0             0             0             0   \n",
              "270892             0             0             0             0             1   \n",
              "270893             0             0             0             0             1   \n",
              "270894             0             0             0             0             0   \n",
              "270895             0             0             0             0             1   \n",
              "\n",
              "        Champion 1_5  Champion 1_6  Level 1  Item 1 1_0  Item 1 1_1  ...  \\\n",
              "0                  0             1        2           0           0  ...   \n",
              "1                  1             0        2           0           0  ...   \n",
              "2                  1             1        2           0           0  ...   \n",
              "3                  0             0        2           0           0  ...   \n",
              "4                  1             0        2           0           0  ...   \n",
              "...              ...           ...      ...         ...         ...  ...   \n",
              "270891             0             1        2           0           0  ...   \n",
              "270892             0             0        3           1           0  ...   \n",
              "270893             0             1        2           0           0  ...   \n",
              "270894             0             1        2           0           0  ...   \n",
              "270895             0             1        2           0           0  ...   \n",
              "\n",
              "        Trait 7_3  Trait 7_4  Tier 7  Trait 8_0  Trait 8_1  Trait 8_2  \\\n",
              "0               0          1       3          0          0          0   \n",
              "1               1          0       0          0          0          0   \n",
              "2               1          0       0          0          0          0   \n",
              "3               1          0       0          0          0          0   \n",
              "4               1          0       0          0          0          0   \n",
              "...           ...        ...     ...        ...        ...        ...   \n",
              "270891          0          1       3          0          0          0   \n",
              "270892          1          0       0          0          0          0   \n",
              "270893          1          0       0          0          0          0   \n",
              "270894          1          0       0          0          0          0   \n",
              "270895          1          0       0          0          0          0   \n",
              "\n",
              "        Trait 8_3  Trait 8_4  Tier 8  Placement  \n",
              "0               0          1       0          1  \n",
              "1               0          1       0          2  \n",
              "2               0          1       0          6  \n",
              "3               0          1       0          4  \n",
              "4               0          1       0          0  \n",
              "...           ...        ...     ...        ...  \n",
              "270891          0          1       0          2  \n",
              "270892          0          1       0          5  \n",
              "270893          0          1       0          6  \n",
              "270894          0          1       0          4  \n",
              "270895          0          1       0          0  \n",
              "\n",
              "[270896 rows x 394 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_data = pd.read_csv('test_dataset_label_encoded.csv', delimiter='\\t') #read in label encoded data\n",
        "label_data['Placement'] = label_data['Placement'] -1 #get placement aka independant variable\n",
        "label_data_traitless = label_data.copy(deep=True).iloc[:,:55] #make a subset without trait data\n",
        "label_data_traitless[\"Placement\"] = label_data['Placement']\n",
        "match_data = pd.read_csv('test_dataset_encoded.csv', delimiter='\\t') #repeat steps for binary encoded data\n",
        "match_data['Placement'] = match_data['Placement'] -1\n",
        "match_data_traitless = label_data.copy(deep=True).iloc[:,:344]\n",
        "match_data_traitless[\"Placement\"] = match_data['Placement']\n",
        "match_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training on the 4 different datasets to see what performs the best before optimizing it**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO5RyQu4QnCQ"
      },
      "outputs": [],
      "source": [
        "train_binary, test_binary = train_test_split(match_data, test_size=0.2, random_state=42, shuffle=True)\n",
        "train_binary_traitless, test_binary_traitless = train_test_split(match_data_traitless, test_size=0.2, random_state=42, shuffle=True)\n",
        "train_label, test_label = train_test_split(label_data, test_size=0.2, random_state=42, shuffle=True)\n",
        "train_label_traitless, test_label_traitless = train_test_split(label_data_traitless, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FErKx5q8QqTl"
      },
      "outputs": [],
      "source": [
        "train_dataset_binary = PandasDataset(train_binary, target_column=\"Placement\")\n",
        "test_dataset_binary = PandasDataset(test_binary, target_column=\"Placement\")\n",
        "\n",
        "    # Create DataLoaders\n",
        "train_loader_binary = DataLoader(train_dataset_binary, batch_size=1024, shuffle=True)\n",
        "test_loader_binary = DataLoader(test_dataset_binary, batch_size=1024, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0RT_HjXbS6N"
      },
      "outputs": [],
      "source": [
        "train_dataset_binary_traitless = PandasDataset(train_binary_traitless, target_column=\"Placement\")\n",
        "test_dataset_binary_traitless = PandasDataset(test_binary_traitless, target_column=\"Placement\")\n",
        "\n",
        "    # Create DataLoaders\n",
        "train_loader_binary_traitless = DataLoader(train_dataset_binary_traitless, batch_size=1024, shuffle=True)\n",
        "test_loader_binary_traitless = DataLoader(test_dataset_binary_traitless, batch_size=1024, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly71JXuXbUmx"
      },
      "outputs": [],
      "source": [
        "train_dataset_label = PandasDataset(train_label, target_column=\"Placement\")\n",
        "test_dataset_label = PandasDataset(test_label, target_column=\"Placement\")\n",
        "\n",
        "    # Create DataLoaders\n",
        "train_loader_label = DataLoader(train_dataset_label, batch_size=1024, shuffle=True)\n",
        "test_loader_label = DataLoader(test_dataset_label, batch_size=1024, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9xFvY5hbVMC"
      },
      "outputs": [],
      "source": [
        "train_dataset_label_traitless = PandasDataset(train_label_traitless, target_column=\"Placement\")\n",
        "test_dataset_label_traitless = PandasDataset(test_label_traitless, target_column=\"Placement\")\n",
        "\n",
        "    # Create DataLoaders\n",
        "train_loader_label_traitless = DataLoader(train_dataset_label_traitless, batch_size=1024, shuffle=True)\n",
        "test_loader_label_traitless = DataLoader(test_dataset_label_traitless, batch_size=1024, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Mgrr4ZTWOM",
        "outputId": "fd71e0f4-f31b-415f-ccd5-0e16695a504c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 0., 1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 3., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
              "         1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 3.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
              "         0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         1., 0., 0., 0., 0., 1., 1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "         0., 1., 1., 2., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "         0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
              "         0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 2., 0., 0., 0., 1., 0.,\n",
              "         1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
              "         1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 2., 0., 0., 0.,\n",
              "         0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.]),\n",
              " tensor(4))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset_binary[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImDiy4yfS7eG"
      },
      "outputs": [],
      "source": [
        "epochs=15\n",
        "crit = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuH-XcB9Tq13",
        "outputId": "2a204241-77f4-4811-c1e6-3f9af09abbb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "Train Loss: 1.8801, Train Score: 0.2381\n",
            "Test Loss: 1.7342, Test Score: 0.2831\n",
            "Epoch 2/15\n",
            "Train Loss: 1.6848, Train Score: 0.2951\n",
            "Test Loss: 1.6657, Test Score: 0.3023\n",
            "Epoch 3/15\n",
            "Train Loss: 1.6586, Train Score: 0.3047\n",
            "Test Loss: 1.6523, Test Score: 0.3119\n",
            "Epoch 4/15\n",
            "Train Loss: 1.6360, Train Score: 0.3110\n",
            "Test Loss: 1.6368, Test Score: 0.3148\n",
            "Epoch 5/15\n",
            "Train Loss: 1.6199, Train Score: 0.3183\n",
            "Test Loss: 1.6404, Test Score: 0.3086\n",
            "Epoch 6/15\n",
            "Train Loss: 1.6145, Train Score: 0.3191\n",
            "Test Loss: 1.6149, Test Score: 0.3190\n",
            "Epoch 7/15\n",
            "Train Loss: 1.5974, Train Score: 0.3265\n",
            "Test Loss: 1.6122, Test Score: 0.3213\n",
            "Epoch 8/15\n",
            "Train Loss: 1.5907, Train Score: 0.3293\n",
            "Test Loss: 1.6174, Test Score: 0.3210\n",
            "Epoch 9/15\n",
            "Train Loss: 1.5854, Train Score: 0.3298\n",
            "Test Loss: 1.6138, Test Score: 0.3181\n",
            "Epoch 10/15\n",
            "Train Loss: 1.5796, Train Score: 0.3330\n",
            "Test Loss: 1.6087, Test Score: 0.3201\n",
            "Epoch 11/15\n",
            "Train Loss: 1.5872, Train Score: 0.3312\n",
            "Test Loss: 1.6239, Test Score: 0.3180\n",
            "Epoch 12/15\n",
            "Train Loss: 1.5832, Train Score: 0.3326\n",
            "Test Loss: 1.6349, Test Score: 0.3183\n",
            "Epoch 13/15\n",
            "Train Loss: 1.5697, Train Score: 0.3370\n",
            "Test Loss: 1.6067, Test Score: 0.3223\n",
            "Epoch 14/15\n",
            "Train Loss: 1.5663, Train Score: 0.3388\n",
            "Test Loss: 1.6195, Test Score: 0.3238\n",
            "Epoch 15/15\n",
            "Train Loss: 1.5551, Train Score: 0.3431\n",
            "Test Loss: 1.6106, Test Score: 0.3237\n"
          ]
        }
      ],
      "source": [
        "binary_model = TransformerMLP(input_dim=len(train_dataset_binary[0][0]), hidden_dim=512).to(device)\n",
        "opt = torch.optim.Adam(binary_model.parameters(), lr=learning_rate)\n",
        "final_test_score = run_model(binary_model, train_loader_binary, test_loader_binary, epochs, crit, opt, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdXX3EXcb90L",
        "outputId": "bcb6787d-6395-4d8a-994e-47fb0a9f25ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "Train Loss: 1.9341, Train Score: 0.2194\n",
            "Test Loss: 1.8567, Test Score: 0.2446\n",
            "Epoch 2/15\n",
            "Train Loss: 1.8443, Train Score: 0.2441\n",
            "Test Loss: 1.8426, Test Score: 0.2463\n",
            "Epoch 3/15\n",
            "Train Loss: 1.8777, Train Score: 0.2324\n",
            "Test Loss: 1.9842, Test Score: 0.1802\n",
            "Epoch 4/15\n",
            "Train Loss: 1.9720, Train Score: 0.2015\n",
            "Test Loss: 1.9279, Test Score: 0.2121\n",
            "Epoch 5/15\n",
            "Train Loss: 1.9544, Train Score: 0.2090\n",
            "Test Loss: 1.9307, Test Score: 0.2199\n",
            "Epoch 6/15\n",
            "Train Loss: 1.9324, Train Score: 0.2167\n",
            "Test Loss: 1.8822, Test Score: 0.2291\n",
            "Epoch 7/15\n",
            "Train Loss: 1.9097, Train Score: 0.2240\n",
            "Test Loss: 1.9073, Test Score: 0.2243\n",
            "Epoch 8/15\n",
            "Train Loss: 1.9554, Train Score: 0.2085\n",
            "Test Loss: 1.9050, Test Score: 0.2287\n",
            "Epoch 9/15\n",
            "Train Loss: 1.9011, Train Score: 0.2253\n",
            "Test Loss: 1.9392, Test Score: 0.2098\n",
            "Epoch 10/15\n",
            "Train Loss: 1.8898, Train Score: 0.2309\n",
            "Test Loss: 1.8563, Test Score: 0.2391\n",
            "Epoch 11/15\n",
            "Train Loss: 1.8601, Train Score: 0.2400\n",
            "Test Loss: 1.8426, Test Score: 0.2449\n",
            "Epoch 12/15\n",
            "Train Loss: 1.8393, Train Score: 0.2459\n",
            "Test Loss: 1.8334, Test Score: 0.2477\n",
            "Epoch 13/15\n",
            "Train Loss: 1.8275, Train Score: 0.2512\n",
            "Test Loss: 1.8318, Test Score: 0.2502\n",
            "Epoch 14/15\n",
            "Train Loss: 1.8217, Train Score: 0.2536\n",
            "Test Loss: 1.8210, Test Score: 0.2530\n",
            "Epoch 15/15\n",
            "Train Loss: 1.8109, Train Score: 0.2560\n",
            "Test Loss: 1.8016, Test Score: 0.2594\n"
          ]
        }
      ],
      "source": [
        "binary_model_traitless = TransformerMLP(input_dim=len(train_dataset_binary_traitless[0][0]), hidden_dim=512).to(device)\n",
        "opt = torch.optim.Adam(binary_model_traitless.parameters(), lr=learning_rate)\n",
        "final_test_score_traitless = run_model(binary_model_traitless, train_loader_binary_traitless, test_loader_binary_traitless, epochs, crit, opt, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8_tYUsTb9qs",
        "outputId": "dd50b136-cd3b-4d7f-fab9-d7cb14699e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "Train Loss: 1.9440, Train Score: 0.2173\n",
            "Test Loss: 1.8468, Test Score: 0.2429\n",
            "Epoch 2/15\n",
            "Train Loss: 1.8311, Train Score: 0.2476\n",
            "Test Loss: 1.8195, Test Score: 0.2493\n",
            "Epoch 3/15\n",
            "Train Loss: 1.8163, Train Score: 0.2538\n",
            "Test Loss: 1.8092, Test Score: 0.2596\n",
            "Epoch 4/15\n",
            "Train Loss: 1.8149, Train Score: 0.2534\n",
            "Test Loss: 1.8028, Test Score: 0.2572\n",
            "Epoch 5/15\n",
            "Train Loss: 1.8620, Train Score: 0.2394\n",
            "Test Loss: 1.9554, Test Score: 0.2065\n",
            "Epoch 6/15\n",
            "Train Loss: 1.9990, Train Score: 0.1862\n",
            "Test Loss: 2.0063, Test Score: 0.1797\n",
            "Epoch 7/15\n",
            "Train Loss: 2.0584, Train Score: 0.1457\n",
            "Test Loss: 2.0797, Test Score: 0.1379\n",
            "Epoch 8/15\n",
            "Train Loss: 2.0426, Train Score: 0.1632\n",
            "Test Loss: 2.0241, Test Score: 0.1807\n",
            "Epoch 9/15\n",
            "Train Loss: 2.0237, Train Score: 0.1722\n",
            "Test Loss: 2.0892, Test Score: 0.1413\n",
            "Epoch 10/15\n",
            "Train Loss: 1.9654, Train Score: 0.2041\n",
            "Test Loss: 2.0433, Test Score: 0.1614\n",
            "Epoch 11/15\n",
            "Train Loss: 1.9383, Train Score: 0.2156\n",
            "Test Loss: 1.9249, Test Score: 0.2221\n",
            "Epoch 12/15\n",
            "Train Loss: 2.0054, Train Score: 0.1848\n",
            "Test Loss: 2.0822, Test Score: 0.1282\n",
            "Epoch 13/15\n",
            "Train Loss: 2.0200, Train Score: 0.1780\n",
            "Test Loss: 1.9354, Test Score: 0.2111\n",
            "Epoch 14/15\n",
            "Train Loss: 1.9596, Train Score: 0.2067\n",
            "Test Loss: 1.9627, Test Score: 0.2006\n",
            "Epoch 15/15\n",
            "Train Loss: 1.9324, Train Score: 0.2173\n",
            "Test Loss: 1.8848, Test Score: 0.2343\n"
          ]
        }
      ],
      "source": [
        "label_model = TransformerMLP(input_dim=len(train_dataset_label[0][0]), hidden_dim=512).to(device)\n",
        "opt = torch.optim.Adam(label_model.parameters(), lr=learning_rate)\n",
        "final_test_score_label = run_model(label_model, train_loader_label, test_loader_label, epochs, crit, opt, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8RryVq7b9hl",
        "outputId": "8472eb56-850f-429f-8bd8-8e6c7eaa75b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "Train Loss: 1.9403, Train Score: 0.2190\n",
            "Test Loss: 1.8428, Test Score: 0.2464\n",
            "Epoch 2/15\n",
            "Train Loss: 1.8520, Train Score: 0.2415\n",
            "Test Loss: 1.8315, Test Score: 0.2480\n",
            "Epoch 3/15\n",
            "Train Loss: 1.8526, Train Score: 0.2418\n",
            "Test Loss: 1.8355, Test Score: 0.2480\n",
            "Epoch 4/15\n",
            "Train Loss: 1.8324, Train Score: 0.2484\n",
            "Test Loss: 1.8200, Test Score: 0.2499\n",
            "Epoch 5/15\n",
            "Train Loss: 1.8145, Train Score: 0.2541\n",
            "Test Loss: 1.8009, Test Score: 0.2581\n",
            "Epoch 6/15\n",
            "Train Loss: 1.8079, Train Score: 0.2573\n",
            "Test Loss: 1.8128, Test Score: 0.2554\n",
            "Epoch 7/15\n",
            "Train Loss: 1.8073, Train Score: 0.2570\n",
            "Test Loss: 1.8007, Test Score: 0.2564\n",
            "Epoch 8/15\n",
            "Train Loss: 1.9857, Train Score: 0.1946\n",
            "Test Loss: 2.0613, Test Score: 0.1407\n",
            "Epoch 9/15\n",
            "Train Loss: 1.9897, Train Score: 0.1934\n",
            "Test Loss: 1.9575, Test Score: 0.2121\n",
            "Epoch 10/15\n",
            "Train Loss: 2.0335, Train Score: 0.1600\n",
            "Test Loss: 2.0781, Test Score: 0.1318\n",
            "Epoch 11/15\n",
            "Train Loss: 2.0441, Train Score: 0.1649\n",
            "Test Loss: 1.9496, Test Score: 0.2080\n",
            "Epoch 12/15\n",
            "Train Loss: 1.9902, Train Score: 0.1943\n",
            "Test Loss: 1.9226, Test Score: 0.2198\n",
            "Epoch 13/15\n",
            "Train Loss: 1.9915, Train Score: 0.1929\n",
            "Test Loss: 1.9471, Test Score: 0.2182\n",
            "Epoch 14/15\n",
            "Train Loss: 1.9557, Train Score: 0.2101\n",
            "Test Loss: 2.0274, Test Score: 0.1741\n",
            "Epoch 15/15\n",
            "Train Loss: 1.9367, Train Score: 0.2151\n",
            "Test Loss: 1.9006, Test Score: 0.2323\n"
          ]
        }
      ],
      "source": [
        "label_model_traitless = TransformerMLP(input_dim=len(train_dataset_label_traitless[0][0]), hidden_dim=512).to(device)\n",
        "opt = torch.optim.Adam(label_model_traitless.parameters(), lr=learning_rate)\n",
        "final_test_score_label_traitless = run_model(label_model_traitless, train_loader_label_traitless, test_loader_label_traitless, epochs, crit, opt, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**binary encoded data with traits performs the best, so optimize on this model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6BNsstZl9Rs",
        "outputId": "a47cb291-4e4a-460e-dfc3-998d991ba1d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:00:06,120] A new study created in memory with name: no-name-582be93f-1f70-4eec-8cb2-2117980fb6f0\n",
            "<ipython-input-35-cd7310807b32>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform(\"dropout\", 0.1, 0.5)\n",
            "<ipython-input-35-cd7310807b32>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 192 4 111 0.14047986072797786 0.017246153310800715 672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:03:20,842] Trial 0 finished with value: 2.124136547555126 and parameters: {'num_heads': 3, 'num_layers': 4, 'ffn_dim': 111, 'dropout': 0.14047986072797786, 'learning_rate': 0.017246153310800715, 'batch_size': 672}. Best is trial 0 with value: 2.124136547555126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.124136547555126, Accuracy: 0.12582827294708282\n",
            "5 480 1 258 0.18821946248479252 0.0005203017550857601 259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:03:58,000] Trial 1 finished with value: 1.7089815598377334 and parameters: {'num_heads': 5, 'num_layers': 1, 'ffn_dim': 258, 'dropout': 0.18821946248479252, 'learning_rate': 0.0005203017550857601, 'batch_size': 259}. Best is trial 1 with value: 1.7089815598377334.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7089815598377334, Accuracy: 0.286831613724875\n",
            "5 320 4 326 0.17191839104102774 1.136690529933134e-05 816\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:05:43,708] Trial 2 finished with value: 1.9942948437274848 and parameters: {'num_heads': 5, 'num_layers': 4, 'ffn_dim': 326, 'dropout': 0.17191839104102774, 'learning_rate': 1.136690529933134e-05, 'batch_size': 816}. Best is trial 1 with value: 1.7089815598377334.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.9942948437274848, Accuracy: 0.1953985861680725\n",
            "8 256 4 336 0.35141918855878584 2.1327296383213623e-05 938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:08:15,162] Trial 3 finished with value: 1.973677069462579 and parameters: {'num_heads': 8, 'num_layers': 4, 'ffn_dim': 336, 'dropout': 0.35141918855878584, 'learning_rate': 2.1327296383213623e-05, 'batch_size': 938}. Best is trial 1 with value: 1.7089815598377334.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.973677069462579, Accuracy: 0.2009819302681851\n",
            "8 512 1 370 0.4024804742361371 0.007105573676308286 392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:09:06,144] Trial 4 finished with value: 2.116543292136994 and parameters: {'num_heads': 8, 'num_layers': 1, 'ffn_dim': 370, 'dropout': 0.4024804742361371, 'learning_rate': 0.007105573676308286, 'batch_size': 392}. Best is trial 1 with value: 1.7089815598377334.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.116543292136994, Accuracy: 0.12549142656748924\n",
            "8 512 1 93 0.43034788125244416 0.0032007947239337414 995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:11:29,250] Trial 5 finished with value: 2.1577177474258145 and parameters: {'num_heads': 8, 'num_layers': 1, 'ffn_dim': 93, 'dropout': 0.43034788125244416, 'learning_rate': 0.0032007947239337414, 'batch_size': 995}. Best is trial 1 with value: 1.7089815598377334.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.1577177474258145, Accuracy: 0.12552372690525848\n",
            "7 448 4 147 0.18868240233749642 0.010564346650278581 789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:25:17,602] Trial 6 finished with value: 2.177641978697343 and parameters: {'num_heads': 7, 'num_layers': 4, 'ffn_dim': 147, 'dropout': 0.18868240233749642, 'learning_rate': 0.010564346650278581, 'batch_size': 789}. Best is trial 1 with value: 1.7089815598377334.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.177641978697343, Accuracy: 0.12489617748574171\n",
            "5 480 4 415 0.2388253061788308 0.011381355998485202 893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:33:55,255] Trial 7 finished with value: 2.2372145741074174 and parameters: {'num_heads': 5, 'num_layers': 4, 'ffn_dim': 415, 'dropout': 0.2388253061788308, 'learning_rate': 0.011381355998485202, 'batch_size': 893}. Best is trial 1 with value: 1.7089815598377334.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.2372145741074174, Accuracy: 0.12482696247623618\n",
            "3 96 1 356 0.3716588248699091 0.01425472832411105 370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:34:07,554] Trial 8 finished with value: 2.0885653320839785 and parameters: {'num_heads': 3, 'num_layers': 1, 'ffn_dim': 356, 'dropout': 0.3716588248699091, 'learning_rate': 0.01425472832411105, 'batch_size': 370}. Best is trial 1 with value: 1.7089815598377334.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.0885653320839785, Accuracy: 0.12660348105354474\n",
            "6 384 3 382 0.3257071906649246 0.008696157285562759 958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:43:48,487] Trial 9 finished with value: 2.1485676030230416 and parameters: {'num_heads': 6, 'num_layers': 3, 'ffn_dim': 382, 'dropout': 0.3257071906649246, 'learning_rate': 0.008696157285562759, 'batch_size': 958}. Best is trial 1 with value: 1.7089815598377334.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.1485676030230416, Accuracy: 0.12574060060170916\n",
            "2 64 2 219 0.2557440528914259 0.00026750052120056307 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:44:41,844] Trial 10 finished with value: 1.6967165302949996 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 219, 'dropout': 0.2557440528914259, 'learning_rate': 0.00026750052120056307, 'batch_size': 26}. Best is trial 10 with value: 1.6967165302949996.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6967165302949996, Accuracy: 0.291432104690009\n",
            "2 64 2 221 0.26170335938408695 0.00015340307314982833 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:45:52,545] Trial 11 finished with value: 1.7021077736964654 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 221, 'dropout': 0.26170335938408695, 'learning_rate': 0.00015340307314982833, 'batch_size': 18}. Best is trial 10 with value: 1.6967165302949996.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7021077736964654, Accuracy: 0.29037080787759095\n",
            "2 256 2 196 0.27298496788546384 0.0001799323549258246 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:47:42,096] Trial 12 finished with value: 1.6985305796644485 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 196, 'dropout': 0.27298496788546384, 'learning_rate': 0.0001799323549258246, 'batch_size': 21}. Best is trial 10 with value: 1.6967165302949996.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6985305796644485, Accuracy: 0.29252108750622935\n",
            "2 256 2 163 0.2810512029808898 0.00010539174662319339 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:49:13,748] Trial 13 finished with value: 1.706155498646157 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 163, 'dropout': 0.2810512029808898, 'learning_rate': 0.00010539174662319339, 'batch_size': 26}. Best is trial 10 with value: 1.6967165302949996.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.706155498646157, Accuracy: 0.2881559275734141\n",
            "3 96 2 208 0.4938552754094862 0.09174409350045439 191\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:49:31,996] Trial 14 finished with value: 2.111247867634643 and parameters: {'num_heads': 3, 'num_layers': 2, 'ffn_dim': 208, 'dropout': 0.4938552754094862, 'learning_rate': 0.09174409350045439, 'batch_size': 191}. Best is trial 10 with value: 1.6967165302949996.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.111247867634643, Accuracy: 0.12448550176267557\n",
            "4 256 3 131 0.22880891429736 0.0005297977920867471 147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:50:20,714] Trial 15 finished with value: 1.7045255020917471 and parameters: {'num_heads': 4, 'num_layers': 3, 'ffn_dim': 131, 'dropout': 0.22880891429736, 'learning_rate': 0.0005297977920867471, 'batch_size': 147}. Best is trial 10 with value: 1.6967165302949996.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7045255020917471, Accuracy: 0.28826205725465587\n",
            "2 64 2 79 0.30233330011045106 9.605509502451262e-05 524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:50:34,728] Trial 16 finished with value: 1.875345260336779 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 79, 'dropout': 0.30233330011045106, 'learning_rate': 9.605509502451262e-05, 'batch_size': 524}. Best is trial 10 with value: 1.6967165302949996.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.875345260336779, Accuracy: 0.2348465272522564\n",
            "4 384 3 512 0.22891145737025695 0.001441174897488019 122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:55:28,604] Trial 17 finished with value: 2.0942680700213034 and parameters: {'num_heads': 4, 'num_layers': 3, 'ffn_dim': 512, 'dropout': 0.22891145737025695, 'learning_rate': 0.001441174897488019, 'batch_size': 122}. Best is trial 10 with value: 1.6967165302949996.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.0942680700213034, Accuracy: 0.12422248472655457\n",
            "4 384 2 250 0.12767808963967553 3.4743062191619445e-05 295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:56:19,487] Trial 18 finished with value: 1.7970478447116152 and parameters: {'num_heads': 4, 'num_layers': 2, 'ffn_dim': 250, 'dropout': 0.12767808963967553, 'learning_rate': 3.4743062191619445e-05, 'batch_size': 295}. Best is trial 10 with value: 1.6967165302949996.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7970478447116152, Accuracy: 0.26311855146828106\n",
            "3 96 3 184 0.3148846750287438 0.0002198628939732341 501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:56:45,128] Trial 19 finished with value: 1.7634741106429772 and parameters: {'num_heads': 3, 'num_layers': 3, 'ffn_dim': 184, 'dropout': 0.3148846750287438, 'learning_rate': 0.0002198628939732341, 'batch_size': 501}. Best is trial 10 with value: 1.6967165302949996.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7634741106429772, Accuracy: 0.27075988851769134\n",
            "2 64 2 276 0.10740856009515329 0.0009321152444711285 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:57:04,134] Trial 20 finished with value: 1.686800765595313 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 276, 'dropout': 0.10740856009515329, 'learning_rate': 0.0009321152444711285, 'batch_size': 100}. Best is trial 20 with value: 1.686800765595313.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.686800765595313, Accuracy: 0.29457908045552705\n",
            "2 128 2 281 0.11159925895512796 0.0004023858299284209 91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:57:30,452] Trial 21 finished with value: 1.6906125712154494 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 281, 'dropout': 0.11159925895512796, 'learning_rate': 0.0004023858299284209, 'batch_size': 91}. Best is trial 20 with value: 1.686800765595313.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6906125712154494, Accuracy: 0.2920181251038225\n",
            "2 64 2 267 0.10042809904090386 0.0011073882093840127 106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:57:49,931] Trial 22 finished with value: 1.6853186340378665 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 267, 'dropout': 0.10042809904090386, 'learning_rate': 0.0011073882093840127, 'batch_size': 106}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6853186340378665, Accuracy: 0.2939930600417136\n",
            "3 288 2 284 0.10202189942314857 0.0014936035530228873 221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:59:24,001] Trial 23 finished with value: 1.7750715895894835 and parameters: {'num_heads': 3, 'num_layers': 2, 'ffn_dim': 284, 'dropout': 0.10202189942314857, 'learning_rate': 0.0014936035530228873, 'batch_size': 221}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7750715895894835, Accuracy: 0.2670684213440632\n",
            "2 64 3 294 0.10500125360179233 0.0031138709404153826 120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 19:59:49,719] Trial 24 finished with value: 1.7349635784412143 and parameters: {'num_heads': 2, 'num_layers': 3, 'ffn_dim': 294, 'dropout': 0.10500125360179233, 'learning_rate': 0.0031138709404153826, 'batch_size': 120}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7349635784412143, Accuracy: 0.27629708927813357\n",
            "3 192 1 485 0.1569234629273978 0.0007509007365453631 386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:00:08,029] Trial 25 finished with value: 1.7079533440362515 and parameters: {'num_heads': 3, 'num_layers': 1, 'ffn_dim': 485, 'dropout': 0.1569234629273978, 'learning_rate': 0.0007509007365453631, 'batch_size': 386}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7079533440362515, Accuracy: 0.28909725170268924\n",
            "4 384 2 247 0.12409853579801597 0.0025273915914982327 313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:04:04,278] Trial 26 finished with value: 2.105617435463579 and parameters: {'num_heads': 4, 'num_layers': 2, 'ffn_dim': 247, 'dropout': 0.12409853579801597, 'learning_rate': 0.0025273915914982327, 'batch_size': 313}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.105617435463579, Accuracy: 0.1255144982373244\n",
            "6 576 3 290 0.19929702153100862 0.0004329153935924633 104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:07:15,393] Trial 27 finished with value: 1.7289750570871094 and parameters: {'num_heads': 6, 'num_layers': 3, 'ffn_dim': 290, 'dropout': 0.19929702153100862, 'learning_rate': 0.0004329153935924633, 'batch_size': 104}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7289750570871094, Accuracy: 0.2782812528839587\n",
            "2 64 2 410 0.15565930877329498 5.446751392754012e-05 488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:07:31,691] Trial 28 finished with value: 1.8868244567613923 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 410, 'dropout': 0.15565930877329498, 'learning_rate': 5.446751392754012e-05, 'batch_size': 488}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.8868244567613923, Accuracy: 0.23068439801399065\n",
            "3 288 1 162 0.13872011897740494 0.028797067532820367 648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:07:55,592] Trial 29 finished with value: 2.2328119448761443 and parameters: {'num_heads': 3, 'num_layers': 1, 'ffn_dim': 162, 'dropout': 0.13872011897740494, 'learning_rate': 0.028797067532820367, 'batch_size': 648}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.2328119448761443, Accuracy: 0.12438860074936783\n",
            "4 256 2 129 0.11594699139570788 0.0011157181656211712 223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:08:27,293] Trial 30 finished with value: 1.7108313874207406 and parameters: {'num_heads': 4, 'num_layers': 2, 'ffn_dim': 129, 'dropout': 0.11594699139570788, 'learning_rate': 0.0011157181656211712, 'batch_size': 223}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7108313874207406, Accuracy: 0.28702541575149043\n",
            "2 128 2 226 0.14806563876731615 0.000257114801484917 77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:08:54,464] Trial 31 finished with value: 1.6986619246365968 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 226, 'dropout': 0.14806563876731615, 'learning_rate': 0.000257114801484917, 'batch_size': 77}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6986619246365968, Accuracy: 0.2909798999612396\n",
            "2 192 2 260 0.17233142758868625 0.0002949411230943191 171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:09:18,101] Trial 32 finished with value: 1.7015791420680868 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 260, 'dropout': 0.17233142758868625, 'learning_rate': 0.0002949411230943191, 'batch_size': 171}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7015791420680868, Accuracy: 0.2890372653611178\n",
            "3 288 2 317 0.20652284473135485 0.0007596812785918264 67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:10:14,535] Trial 33 finished with value: 1.695754340406179 and parameters: {'num_heads': 3, 'num_layers': 2, 'ffn_dim': 317, 'dropout': 0.20652284473135485, 'learning_rate': 0.0007596812785918264, 'batch_size': 67}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.695754340406179, Accuracy: 0.2903892652134591\n",
            "3 192 1 325 0.2026157455386579 0.0007799974553424931 80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:10:35,898] Trial 34 finished with value: 1.6937003683982277 and parameters: {'num_heads': 3, 'num_layers': 1, 'ffn_dim': 325, 'dropout': 0.2026157455386579, 'learning_rate': 0.0007799974553424931, 'batch_size': 80}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6937003683982277, Accuracy: 0.29118293065578915\n",
            "3 192 1 438 0.17289177630365454 0.001844783068635161 262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:10:51,155] Trial 35 finished with value: 1.7103967037465837 and parameters: {'num_heads': 3, 'num_layers': 1, 'ffn_dim': 438, 'dropout': 0.17289177630365454, 'learning_rate': 0.001844783068635161, 'batch_size': 262}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7103967037465837, Accuracy: 0.28730227578951256\n",
            "2 64 1 321 0.13576650777643698 0.0049653342865718314 172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:11:07,274] Trial 36 finished with value: 1.736779081348389 and parameters: {'num_heads': 2, 'num_layers': 1, 'ffn_dim': 321, 'dropout': 0.13576650777643698, 'learning_rate': 0.0049653342865718314, 'batch_size': 172}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.736779081348389, Accuracy: 0.27711844072426584\n",
            "5 320 1 268 0.11301272297973128 0.0004827970929838882 236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:11:31,669] Trial 37 finished with value: 1.704487774006301 and parameters: {'num_heads': 5, 'num_layers': 1, 'ffn_dim': 268, 'dropout': 0.11301272297973128, 'learning_rate': 0.0004827970929838882, 'batch_size': 236}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.704487774006301, Accuracy: 0.28948024142195317\n",
            "3 192 1 324 0.2118334864146117 0.004682155023697413 324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:11:55,293] Trial 38 finished with value: 1.88580549333484 and parameters: {'num_heads': 3, 'num_layers': 1, 'ffn_dim': 324, 'dropout': 0.2118334864146117, 'learning_rate': 0.004682155023697413, 'batch_size': 324}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.88580549333484, Accuracy: 0.22687295815721958\n",
            "2 192 1 64 0.10020514550588763 0.0007705627872818164 438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:12:09,203] Trial 39 finished with value: 1.7167881370794893 and parameters: {'num_heads': 2, 'num_layers': 1, 'ffn_dim': 64, 'dropout': 0.10020514550588763, 'learning_rate': 0.0007705627872818164, 'batch_size': 438}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7167881370794893, Accuracy: 0.2868731427305783\n",
            "3 96 3 363 0.17942874334811182 0.00225071021585248 587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:12:37,760] Trial 40 finished with value: 1.7728704152880488 and parameters: {'num_heads': 3, 'num_layers': 3, 'ffn_dim': 363, 'dropout': 0.17942874334811182, 'learning_rate': 0.00225071021585248, 'batch_size': 587}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7728704152880488, Accuracy: 0.26342771184407243\n",
            "3 96 2 306 0.211905873428864 0.000852326099308739 72\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:13:04,171] Trial 41 finished with value: 1.6933870955559107 and parameters: {'num_heads': 3, 'num_layers': 2, 'ffn_dim': 306, 'dropout': 0.211905873428864, 'learning_rate': 0.000852326099308739, 'batch_size': 72}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6933870955559107, Accuracy: 0.2916212923826575\n",
            "2 128 2 244 0.1568028165528944 0.0012029917648594033 72\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:13:33,341] Trial 42 finished with value: 1.69391501330062 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 244, 'dropout': 0.1568028165528944, 'learning_rate': 0.0012029917648594033, 'batch_size': 72}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.69391501330062, Accuracy: 0.29028774986618433\n",
            "4 384 2 347 0.13633083588176995 0.0004682591974403443 88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:14:44,761] Trial 43 finished with value: 1.692640054579242 and parameters: {'num_heads': 4, 'num_layers': 2, 'ffn_dim': 347, 'dropout': 0.13633083588176995, 'learning_rate': 0.0004682591974403443, 'batch_size': 88}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.692640054579242, Accuracy: 0.2918935380867126\n",
            "4 128 2 386 0.13220872438082296 0.0003971753440659656 148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:15:06,867] Trial 44 finished with value: 1.6991397132645696 and parameters: {'num_heads': 4, 'num_layers': 2, 'ffn_dim': 386, 'dropout': 0.13220872438082296, 'learning_rate': 0.0003971753440659656, 'batch_size': 148}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6991397132645696, Accuracy: 0.28960944277303013\n",
            "4 256 2 450 0.11977242827096264 0.004445385773734572 810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:17:15,994] Trial 45 finished with value: 2.120678971952467 and parameters: {'num_heads': 4, 'num_layers': 2, 'ffn_dim': 450, 'dropout': 0.11977242827096264, 'learning_rate': 0.004445385773734572, 'batch_size': 810}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.120678971952467, Accuracy: 0.1254314402259178\n",
            "2 64 2 294 0.14845570208201786 1.1752533823194516e-05 209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:17:29,484] Trial 46 finished with value: 2.01342944905751 and parameters: {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 294, 'dropout': 0.14845570208201786, 'learning_rate': 1.1752533823194516e-05, 'batch_size': 209}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.01342944905751, Accuracy: 0.19030436146846563\n",
            "5 320 2 354 0.18956105019797825 0.00010701832756471199 270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:18:11,494] Trial 47 finished with value: 1.7308268034888679 and parameters: {'num_heads': 5, 'num_layers': 2, 'ffn_dim': 354, 'dropout': 0.18956105019797825, 'learning_rate': 0.00010701832756471199, 'batch_size': 270}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7308268034888679, Accuracy: 0.28114213994352055\n",
            "3 192 3 230 0.16697663162953597 0.0005998757494016452 48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:19:12,363] Trial 48 finished with value: 1.6932455801620567 and parameters: {'num_heads': 3, 'num_layers': 3, 'ffn_dim': 230, 'dropout': 0.16697663162953597, 'learning_rate': 0.0005998757494016452, 'batch_size': 48}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6932455801620567, Accuracy: 0.29158899204488825\n",
            "6 384 3 229 0.3543911100502931 0.00035628653913875055 125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-12 20:20:33,981] Trial 49 finished with value: 1.7068649351665581 and parameters: {'num_heads': 6, 'num_layers': 3, 'ffn_dim': 229, 'dropout': 0.3543911100502931, 'learning_rate': 0.00035628653913875055, 'batch_size': 125}. Best is trial 22 with value: 1.6853186340378665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7068649351665581, Accuracy: 0.2884420162793702\n",
            "Best hyperparameters found:  {'num_heads': 2, 'num_layers': 2, 'ffn_dim': 267, 'dropout': 0.10042809904090386, 'learning_rate': 0.0011073882093840127, 'batch_size': 106}\n"
          ]
        }
      ],
      "source": [
        "def objective(trial):\n",
        "  num_heads = trial.suggest_int(\"num_heads\", 2, 8)\n",
        "  random_integer = random.randint(32, 128)\n",
        "  hidden_dim = (random_integer // 32) * 32 * num_heads\n",
        "  num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "  ffn_dim = trial.suggest_int(\"ffn_dim\", 64, 512, log=True)\n",
        "  dropout = trial.suggest_uniform(\"dropout\", 0.1, 0.5)\n",
        "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
        "  batch_size = trial.suggest_int(\"batch_size\", 16, 1024)\n",
        "\n",
        "  input_dim=len(train_dataset_binary[0][0])\n",
        "  best_model = TransformerMLP(input_dim=input_dim,\n",
        "                              hidden_dim=hidden_dim,\n",
        "                              num_heads=num_heads,\n",
        "                              num_layers=num_layers,\n",
        "                              ffn_dim=ffn_dim,\n",
        "                              dropout=dropout,\n",
        "                              output_dim=8)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(best_model.parameters(), lr=learning_rate)\n",
        "\n",
        "  train_loader_binary_best = DataLoader(train_dataset_binary, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  best_model.train()\n",
        "  running_loss = 0.0\n",
        "  correct_preds = 0\n",
        "  total_preds = 0\n",
        "  print(num_heads, hidden_dim, num_layers, ffn_dim, dropout, learning_rate, batch_size)\n",
        "  for inputs, labels in train_loader_binary_best:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = best_model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # Backpropagation\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # Calculate accuracy\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total_preds += labels.size(0)\n",
        "      correct_preds += (predicted == labels).sum().item()\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = correct_preds / total_preds\n",
        "  print(f\"Loss: {running_loss / len(train_loader_binary_best)}, Accuracy: {accuracy}\")\n",
        "\n",
        "  # Return the loss as the value to optimize\n",
        "  return running_loss / len(train_loader_binary_best)\n",
        "\n",
        "# Create an Optuna study\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Output the best hyperparameters found by Optuna\n",
        "print(\"Best hyperparameters found: \", study.best_trial.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Now build model given optimal hyperparameters according to optuna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdPv6EFXnMbV",
        "outputId": "043801b1-d1fa-4b06-c00c-250d6274306f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "Train Loss: 1.7485, Train Score: 0.2760\n",
            "Test Loss: 1.6642, Test Score: 0.3057\n",
            "Epoch 2/15\n",
            "Train Loss: 1.6443, Train Score: 0.3091\n",
            "Test Loss: 1.6341, Test Score: 0.3166\n",
            "Epoch 3/15\n",
            "Train Loss: 1.6204, Train Score: 0.3188\n",
            "Test Loss: 1.6261, Test Score: 0.3170\n",
            "Epoch 4/15\n",
            "Train Loss: 1.6024, Train Score: 0.3252\n",
            "Test Loss: 1.6394, Test Score: 0.3110\n",
            "Epoch 5/15\n",
            "Train Loss: 1.5898, Train Score: 0.3299\n",
            "Test Loss: 1.6068, Test Score: 0.3223\n",
            "Epoch 6/15\n",
            "Train Loss: 1.5806, Train Score: 0.3329\n",
            "Test Loss: 1.6084, Test Score: 0.3221\n",
            "Epoch 7/15\n",
            "Train Loss: 1.5711, Train Score: 0.3376\n",
            "Test Loss: 1.5994, Test Score: 0.3243\n",
            "Epoch 8/15\n",
            "Train Loss: 1.5619, Train Score: 0.3420\n",
            "Test Loss: 1.6018, Test Score: 0.3240\n",
            "Epoch 9/15\n",
            "Train Loss: 1.5524, Train Score: 0.3453\n",
            "Test Loss: 1.6044, Test Score: 0.3219\n",
            "Epoch 10/15\n",
            "Train Loss: 1.5459, Train Score: 0.3478\n",
            "Test Loss: 1.6044, Test Score: 0.3203\n",
            "Epoch 11/15\n",
            "Train Loss: 1.5375, Train Score: 0.3528\n",
            "Test Loss: 1.6007, Test Score: 0.3237\n",
            "Epoch 12/15\n",
            "Train Loss: 1.5293, Train Score: 0.3566\n",
            "Test Loss: 1.6083, Test Score: 0.3200\n",
            "Epoch 13/15\n",
            "Train Loss: 1.5226, Train Score: 0.3600\n",
            "Test Loss: 1.6073, Test Score: 0.3214\n",
            "Epoch 14/15\n",
            "Train Loss: 1.5167, Train Score: 0.3631\n",
            "Test Loss: 1.6121, Test Score: 0.3233\n",
            "Epoch 15/15\n",
            "Train Loss: 1.5083, Train Score: 0.3666\n",
            "Test Loss: 1.6135, Test Score: 0.3211\n"
          ]
        }
      ],
      "source": [
        "binary_model_best = TransformerMLP(input_dim=len(train_dataset_binary[0][0]), hidden_dim=64, num_heads=2, num_layers=2, ffn_dim=267, dropout=.1004, output_dim=8).to(device)\n",
        "opt = torch.optim.Adam(binary_model_best.parameters(), lr=0.0011079)\n",
        "final_test_score = run_model(binary_model_best, train_loader_binary, test_loader_binary, epochs, crit, opt, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
